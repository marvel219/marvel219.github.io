[{"id":"553b82e172f4d964b59dbfe1955f16b7","title":"关于node版本切换","content":"一、安装gnvm1、要用管理员权限启动cmd；2.确保node是空闲的（将使用中的node关闭）\n2、安装gnvm：\n　　gnvm下载地址:32-bit | 64-bit Github  （1）下载完以后会有一个gnvm.exe 文件  （2）将gnvm.exe 文件放在Node.js 所在的文件夹，3、验证gnvm是否可用：\n 使用指令      gnvm version\n二、gnvm相关指令1、安装多个 node 版本\ngnvm install latest     // 安装最新版本的 node \n　　gnvm install 10.0.0     // 安装指定版本，也可以指定安装32位或64位，eg: gnvm install 10.0.0-x64\n　　gnvm update latest     // 更新本地 latest 的 node 版本\n\n````\n2、卸载任意版本的 node\n ``` bash \n　gnvm uninstall latest    // 卸载最新版本的 node \n　　gnvm uninstall 10.0.0   // 卸载指定版本\n3、查看本地所有安装的 node 版本\n　gnvm ls\n4、切换任意版本的 node\n　gnvm use 10.0.0\n5、安装 npm\n　gnvm npm latest","slug":"关于node版本切换","date":"2022-05-31T13:41:31.000Z","categories_index":"","tags_index":"node - 版本问题","author_index":"Marvel219"},{"id":"8c51d066e7d2fc874045ea6355531a49","title":"关于http","content":"认识 HTTP首先你听的最多的应该就是 HTTP 是一种 超文本传输协议(Hypertext Transfer Protocol)，这你一定能说出来，但是这样还不够超文本传输协议可以进行文字分割：超文本（Hypertext）、传输（Transfer）、协议（Protocol）按照范围的大小 协议 &gt; 传输 &gt; 超文本。下面就分别对这三个名次做一个解释。\n什么是超文本在互联网早期的时候，我们输入的信息只能保存在本地，无法和其他电脑进行交互。我们保存的信息通常都以文本即简单字符的形式存在，文本是一种能够被计算机解析的有意义的二进制数据包。而随着互联网的高速发展，两台电脑之间能够进行数据的传输后，人们不满足只能在两台电脑之间传输文字，还想要传输图片、音频、视频，甚至点击文字或图片能够进行超链接的跳转，那么文本的语义就被扩大了，这种语义扩大后的文本就被称为超文本(Hypertext)。\n什么是传输那么我们上面说到，两台计算机之间会形成互联关系进行通信，我们存储的超文本会被解析成为二进制数据包，由传输载体（例如同轴电缆，电话线，光缆）负责把二进制数据包由计算机终端传输到另一个终端的过程（对终端的详细解释可以参考 你说你懂互联网，那这些你知道么？这篇文章）称为传输(transfer)。\n什么是协议协议这个名词不仅局限于互联网范畴，也体现在日常生活中，比如情侣双方约定好在哪个地点吃饭，这个约定也是一种协议，比如你应聘成功了，企业会和你签订劳动合同，这种双方的雇佣关系也是一种 协议。注意自己一个人对自己的约定不能成为协议，协议的前提条件必须是多人约定。\n那么网络协议是什么呢？\n网络协议就是网络中(包括互联网)传递、管理信息的一些规范。如同人与人之间相互交流是需要遵循一定的规矩一样，计算机之间的相互通信需要共同遵守一定的规则，这些规则就称为网络协议。\n没有网络协议的互联网是混乱的，就和人类社会一样，人不能想怎么样就怎么样，你的行为约束是受到法律的约束的；那么互联网中的端系统也不能自己想发什么发什么，也是需要受到通信协议约束的。\n那么我们就可以总结一下，什么是 HTTP？可以用下面这个经典的总结回答一下： HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范\n与 HTTP 有关的组件随着网络世界演进，HTTP 协议已经几乎成为不可替代的一种协议，在了解了 HTTP 的基本组成后，下面再来带你进一步认识一下 HTTP 协议。\n网络模型网络是一个复杂的系统，不仅包括大量的应用程序、端系统、通信链路、分组交换机等，还有各种各样的协议组成，那么现在我们就来聊一下网络中的协议层次。\n为了给网络协议的设计提供一个结构，网络设计者以分层(layer)的方式组织协议，每个协议属于层次模型之一。每一层都是向它的上一层提供服务(service)，即所谓的服务模型(service model)。每个分层中所有的协议称为 协议栈(protocol stack)。因特网的协议栈由五个部分组成：物理层、链路层、网络层、运输层和应用层。我们采用自上而下的方法研究其原理，也就是应用层 -&gt; 物理层的方式。\n应用层应用层是网络应用程序和网络协议存放的分层，因特网的应用层包括许多协议，例如我们学 web 离不开的 HTTP，电子邮件传送协议 SMTP、端系统文件上传协议 FTP、还有为我们进行域名解析的 DNS 协议。应用层协议分布在多个端系统上，一个端系统应用程序与另外一个端系统应用程序交换信息分组，我们把位于应用层的信息分组称为 报文(message)。\n运输层因特网的运输层在应用程序断点之间传送应用程序报文，在这一层主要有两种传输协议 TCP和 UDP，利用这两者中的任何一个都能够传输报文，不过这两种协议有巨大的不同。\nTCP 向它的应用程序提供了面向连接的服务，它能够控制并确认报文是否到达，并提供了拥塞机制来控制网络传输，因此当网络拥塞时，会抑制其传输速率。\nUDP 协议向它的应用程序提供了无连接服务。它不具备可靠性的特征，没有流量控制，也没有拥塞控制。我们把运输层的分组称为 报文段(segment)\n网络层因特网的网络层负责将称为 数据报(datagram) 的网络分层从一台主机移动到另一台主机。网络层一个非常重要的协议是 IP 协议，所有具有网络层的因特网组件都必须运行 IP 协议，IP 协议是一种网际协议，除了 IP 协议外，网络层还包括一些其他网际协议和路由选择协议，一般把网络层就称为 IP 层，由此可知 IP 协议的重要性。\n链路层现在我们有应用程序通信的协议，有了给应用程序提供运输的协议，还有了用于约定发送位置的 IP 协议，那么如何才能真正的发送数据呢？为了将分组从一个节点（主机或路由器）运输到另一个节点，网络层必须依靠链路层提供服务。链路层的例子包括以太网、WiFi 和电缆接入的 DOCSIS 协议，因为数据从源目的地传送通常需要经过几条链路，一个数据包可能被沿途不同的链路层协议处理，我们把链路层的分组称为 帧(frame)\n物理层然链路层的作用是将帧从一个端系统运输到另一个端系统，而物理层的作用是将帧中的一个个 比特 从一个节点运输到另一个节点，物理层的协议仍然使用链路层协议，这些协议与实际的物理传输介质有关，例如，以太网有很多物理层协议：关于双绞铜线、关于同轴电缆、关于光纤等等。\n","slug":"关于http","date":"2022-05-31T13:35:20.000Z","categories_index":"","tags_index":"http,网络","author_index":"Marvel219"},{"id":"7c3a6f7ad545b7833c547c40303b5d4d","title":"网络爬虫/相关工具与知识","content":"网络爬虫网络爬虫(web crawler), 以前经常称为网络蜘蛛(spider), 是按照一定的规则自动浏览万维网并获取信息的机器人程序(或叫脚本), 曾经被广泛的应用于互联网搜索引擎.使用过互联网和浏览器的人都知道, 网页中除了提供用户阅读的文字信息之外, 还包含一些超链接. 网络爬虫系统正是通过网页中的超链接信息不断获得网络上的其他页面. 正因为如此, 网络数据采集的过程就像一个爬虫或者蜘蛛在网络上漫游, 所有才被形象的称之为网络爬虫或者网络蜘蛛.\n爬虫的应用领域在理想的状态下, 所有的ICP(internet Content Provider) 都应该为自己的网络提供API接口来共享它们允许其他程序获取的数据, 在这种情况下爬虫就不是必需品, 国内比较有名的电商平台(如淘宝, 京东等), 社交平台(如QQ&#x2F;微博&#x2F;微信等)这些网站都提供了自己的Open Api, 但是这类Open Api通常会对可以抓取的数据频率进行限制. 对于大多数的公司而言, 计时的获取行业相关数据就是企业生存的重要环节之一, 然而大部分企业在行业数据方面的匮乏是其与生俱来的短板, 合理的利用爬虫来获取数据并从中提取出有价值的信息是至关重要的. 当然爬虫还有很多重要的应用灵玉, 以下列举了其中一部分.\n1. 搜索引擎\n2. 新闻聚合\n3. 社交应用\n4. 舆情监控\n5. 行业数据\nRbots.txt文件大多数网站都会定义robots.txt文件, 下面以淘宝的robots.txt文件为例, 看看该网站对爬虫有哪些限制\n$User-agent:  Baiduspider\nAllow:  /article\nAllow:  /oshtml\nDisallow:  /product/\nDisallow:  /\n\nUser-Agent:  Googlebot\nAllow:  /article\nAllow:  /oshtml\nAllow:  /product\nAllow:  /spu\nAllow:  /dianpu\nAllow:  /oversea\nAllow:  /list\nDisallow:  /\n\nUser-agent:  Bingbot\nAllow:  /article\nAllow:  /oshtml\nAllow:  /product\nAllow:  /spu\nAllow:  /dianpu\nAllow:  /oversea\nAllow:  /list\nDisallow:  /\n\nUser-Agent:  360Spider\nAllow:  /article\nAllow:  /oshtml\nDisallow:  /\n\nUser-Agent:  Yisouspider\nAllow:  /article\nAllow:  /oshtml\nDisallow:  /\n\nUser-Agent:  Sogouspider\nAllow:  /article\nAllow:  /oshtml\nAllow:  /product\nDisallow:  /\n\nUser-Agent:  Yahoo!  Slurp\nAllow:  /product\nAllow:  /spu\nAllow:  /dianpu\nAllow:  /oversea\nAllow:  /list\nDisallow:  /\n\nUser-Agent:  *\nDisallow:  /\n注意上面robots.txt第一段的最后一行, 通过设置’Disallow:&#x2F;’禁止百度爬虫访问除了’Allow’规定页面外的其他所有页面. 因此当你在百度搜索’淘宝’的时候, 搜索结果下方会出现: ‘由于该网站的rebots.txt文件存在限制指令(限制搜索引擎抓取). 系统无法提供该页面的内容描述.’, 百度作为一个搜索引擎, 至少在表面上遵守了淘宝网的robots.txt协议, 所以用户不能从百度上搜索到淘宝内部的产品信息.\n相关工具介绍在开始讲解爬虫之前，我们稍微对HTTP（超文本传输协议）做一些回顾，因为我们在网页上看到的内容通常是浏览器执行HTML语言得到的结果，而HTTP就是传输HTML数据的协议。HTTP是构建于TCP（传输控制协议）之上应用级协议，它利用了TCP提供的可靠的传输服务实现了Web应用中的数据交换。按照维基百科上的介绍，设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法，也就是说这个协议是浏览器和Web服务器之间传输的数据的载体。关于这个协议的详细信息以及目前的发展状况，大家可以阅读阮一峰老师的《HTTP 协议入门》、《互联网协议入门》系列以及《图解HTTPS协议》进行了解，下图是我在2009年9月10日凌晨4点在四川省网络通信技术重点实验室用开源协议分析工具Ethereal（抓包工具WireShark的前身）截取的访问百度首页时的HTTP请求和响应的报文（协议数据），由于Ethereal截取的是经过网络适配器的数据，因此可以清晰的看到从物理链路层到应用层的协议数据。\n相关工具1.Chrome Developer Tools\n开发推荐使用谷歌浏览器, 这是谷歌的开发者工具\n2.HTTPie\n$ http --header http://www.scu.edu.cn\nHTTP/1.1 200 OK\nAccept-Ranges: bytes\nCache-Control: private, max-age=600\nConnection: Keep-Alive\nContent-Encoding: gzip\nContent-Language: zh-CN\nContent-Length: 14403\nContent-Type: text/html\nDate: Sun, 27 May 2018 15:38:25 GMT\nETag: \"e6ec-56d3032d70a32-gzip\"\nExpires: Sun, 27 May 2018 15:48:25 GMT\nKeep-Alive: timeout=5, max=100\nLast-Modified: Sun, 27 May 2018 13:44:22 GMT\nServer: VWebServer\nVary: User-Agent,Accept-Encoding\nX-Frame-Options: SAMEORIGIN\n3.BuiltWith(python自带的模块): 识别网站使用的技术\n>>>\n>>> import builtwith\n>>> builtwith.parse('http://www.bootcss.com/')\n&#123;'web-servers': ['Nginx'], 'font-scripts': ['Font Awesome'], 'javascript-frameworks': ['Lo-dash', 'Underscore.js', 'Vue.js', 'Zepto', 'jQuery'], 'web-frameworks': ['Twitter Bootstrap']&#125;\n\n>>>\n>>> import ssl\n>>> ssl._create_default_https_context = ssl._create_unverified_context\n>>> builtwith.parse('https://www.jianshu.com/')\n&#123;'web-servers': ['Tengine'], 'web-frameworks': ['Twitter Bootstrap', 'Ruby on Rails'], 'programming-languages': ['Ruby']&#125;\n\n4.robotparser: 解析robots.txt的工具\n>>> from urllib import robotparser\n>>> parser = robotparser.RobotFileParser()\n>>> parser.set_url('https://www.taobao.com/robots.txt')\n>>> parser.read()\n>>> parser.can_fetch('Hellokitty', 'http://www.taobao.com/article')\nFalse\n>>> parser.can_fetch('Baiduspider', 'http://www.taobao.com/article')\nTrue\n>>> parser.can_fetch('Baiduspider', 'http://www.taobao.com/product')\nFalse","slug":"newpaper","date":"2022-05-30T08:49:18.000Z","categories_index":"","tags_index":"网络爬虫","author_index":"Marvel219"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new \"My New Post\"\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2022-05-07T08:37:49.618Z","categories_index":"","tags_index":"test,hello world","author_index":"Marvel219"}]